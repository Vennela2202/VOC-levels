{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef063327",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d99caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4790, 18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "df = pd.read_csv(r\"airquality.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfdb106",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997cb28",
   "metadata": {},
   "source": [
    "## Handing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f3d2a",
   "metadata": {},
   "source": [
    "### checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e728eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units1 0.58455 % missing values\n",
      "HRV_Types 0.58455 % missing values\n",
      "Name 61.4405 % missing values\n"
     ]
    }
   ],
   "source": [
    "##these are the features with nan value\n",
    "features_with_na=[features for features in df.columns if df[features].isnull().sum()>=1]\n",
    "for feature in features_with_na:\n",
    "    print(feature,np.round(df[feature].isnull().mean()*100,5), '% missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a143b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Units1', 'HRV_Types', 'Name']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_with_na\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f931b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the missing HRV_Types with the most frequent type\n",
    "mode_hrv_types = df['HRV_Types'].mode()[0]\n",
    "df['HRV_Types'].fillna(mode_hrv_types, inplace=True)\n",
    "#the most repeated HRV type is REL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f34bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To replace the null values of the Name column, A new category Unknown is created and replaced.\n",
    "df['Name'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d80fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update missing values in Units1 with 'ug/m3'\n",
    "df['Units1'].fillna('ug/m3', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ae853d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectID       0\n",
       "Date           0\n",
       "Sample_ID      0\n",
       "Parameter      0\n",
       "Results        0\n",
       "Units          0\n",
       "CAS            0\n",
       "HRV            0\n",
       "Units1         0\n",
       "HRV_Types      0\n",
       "Name           0\n",
       "Description    0\n",
       "Address        0\n",
       "City_1         0\n",
       "State          0\n",
       "Zip            0\n",
       "x              0\n",
       "y              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eda994",
   "metadata": {},
   "source": [
    "#### 3.2 Other Data Cleaning steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9fb60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83c83bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Results</th>\n",
       "      <th>Units</th>\n",
       "      <th>CAS</th>\n",
       "      <th>HRV</th>\n",
       "      <th>Units1</th>\n",
       "      <th>HRV_Types</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Address</th>\n",
       "      <th>City_1</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Nov13</td>\n",
       "      <td>0005Nov13</td>\n",
       "      <td>1,2,4-Trimethylbenzene</td>\n",
       "      <td>1.40</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>95-63-6</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>REL</td>\n",
       "      <td>Smyth Companies LLC - Minneapolis NE</td>\n",
       "      <td>business</td>\n",
       "      <td>2300 26th St E</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>MN</td>\n",
       "      <td>55406</td>\n",
       "      <td>-1.037933e+07</td>\n",
       "      <td>5.614534e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nov13</td>\n",
       "      <td>0005Nov13</td>\n",
       "      <td>2-Propanol</td>\n",
       "      <td>87.60</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>67-63-0</td>\n",
       "      <td>980000.0</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>REL</td>\n",
       "      <td>Smyth Companies LLC - Minneapolis NE</td>\n",
       "      <td>business</td>\n",
       "      <td>2300 26th St E</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>MN</td>\n",
       "      <td>55406</td>\n",
       "      <td>-1.037933e+07</td>\n",
       "      <td>5.614534e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nov13</td>\n",
       "      <td>0005Nov13</td>\n",
       "      <td>Acetone</td>\n",
       "      <td>8.40</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>67-64-1</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>REL</td>\n",
       "      <td>Smyth Companies LLC - Minneapolis NE</td>\n",
       "      <td>business</td>\n",
       "      <td>2300 26th St E</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>MN</td>\n",
       "      <td>55406</td>\n",
       "      <td>-1.037933e+07</td>\n",
       "      <td>5.614534e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nov13</td>\n",
       "      <td>0005Nov13</td>\n",
       "      <td>Benzene</td>\n",
       "      <td>0.87</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>71-43-2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>HRV</td>\n",
       "      <td>Smyth Companies LLC - Minneapolis NE</td>\n",
       "      <td>business</td>\n",
       "      <td>2300 26th St E</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>MN</td>\n",
       "      <td>55406</td>\n",
       "      <td>-1.037933e+07</td>\n",
       "      <td>5.614534e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nov13</td>\n",
       "      <td>0005Nov13</td>\n",
       "      <td>Chloromethane</td>\n",
       "      <td>0.63</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>74-87-3</td>\n",
       "      <td>206544.0</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>PEL</td>\n",
       "      <td>Smyth Companies LLC - Minneapolis NE</td>\n",
       "      <td>business</td>\n",
       "      <td>2300 26th St E</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>MN</td>\n",
       "      <td>55406</td>\n",
       "      <td>-1.037933e+07</td>\n",
       "      <td>5.614534e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectID   Date  Sample_ID               Parameter  Results  Units  \\\n",
       "0         1  Nov13  0005Nov13  1,2,4-Trimethylbenzene     1.40  ug/m3   \n",
       "1         2  Nov13  0005Nov13              2-Propanol    87.60  ug/m3   \n",
       "2         3  Nov13  0005Nov13                 Acetone     8.40  ug/m3   \n",
       "3         4  Nov13  0005Nov13                 Benzene     0.87  ug/m3   \n",
       "4         5  Nov13  0005Nov13           Chloromethane     0.63  ug/m3   \n",
       "\n",
       "       CAS       HRV Units1 HRV_Types                                  Name  \\\n",
       "0  95-63-6  125000.0  ug/m3       REL  Smyth Companies LLC - Minneapolis NE   \n",
       "1  67-63-0  980000.0  ug/m3       REL  Smyth Companies LLC - Minneapolis NE   \n",
       "2  67-64-1  590000.0  ug/m3       REL  Smyth Companies LLC - Minneapolis NE   \n",
       "3  71-43-2       1.3  ug/m3       HRV  Smyth Companies LLC - Minneapolis NE   \n",
       "4  74-87-3  206544.0  ug/m3       PEL  Smyth Companies LLC - Minneapolis NE   \n",
       "\n",
       "  Description         Address       City_1 State    Zip             x  \\\n",
       "0    business  2300 26th St E  Minneapolis    MN  55406 -1.037933e+07   \n",
       "1    business  2300 26th St E  Minneapolis    MN  55406 -1.037933e+07   \n",
       "2    business  2300 26th St E  Minneapolis    MN  55406 -1.037933e+07   \n",
       "3    business  2300 26th St E  Minneapolis    MN  55406 -1.037933e+07   \n",
       "4    business  2300 26th St E  Minneapolis    MN  55406 -1.037933e+07   \n",
       "\n",
       "              y  \n",
       "0  5.614534e+06  \n",
       "1  5.614534e+06  \n",
       "2  5.614534e+06  \n",
       "3  5.614534e+06  \n",
       "4  5.614534e+06  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe978b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ObjectID', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83b07777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Sample_ID', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "395c971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Units', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b3fb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Units1', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "811a6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('x', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8a3d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('y', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbc6549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Name', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c09b046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Address', inplace=True, axis=1)\n",
    "df.drop('City_1', inplace=True, axis=1)\n",
    "\n",
    "df.drop('State', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "945e5886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Results</th>\n",
       "      <th>CAS</th>\n",
       "      <th>HRV</th>\n",
       "      <th>HRV_Types</th>\n",
       "      <th>Description</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1,2,4-Trimethylbenzene</td>\n",
       "      <td>1.40</td>\n",
       "      <td>95-63-6</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>REL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2-Propanol</td>\n",
       "      <td>87.60</td>\n",
       "      <td>67-63-0</td>\n",
       "      <td>980000.0</td>\n",
       "      <td>REL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Acetone</td>\n",
       "      <td>8.40</td>\n",
       "      <td>67-64-1</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>REL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Benzene</td>\n",
       "      <td>0.87</td>\n",
       "      <td>71-43-2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>HRV</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Chloromethane</td>\n",
       "      <td>0.63</td>\n",
       "      <td>74-87-3</td>\n",
       "      <td>206544.0</td>\n",
       "      <td>PEL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date               Parameter  Results      CAS       HRV HRV_Types  \\\n",
       "0     4  1,2,4-Trimethylbenzene     1.40  95-63-6  125000.0       REL   \n",
       "1     4              2-Propanol    87.60  67-63-0  980000.0       REL   \n",
       "2     4                 Acetone     8.40  67-64-1  590000.0       REL   \n",
       "3     4                 Benzene     0.87  71-43-2       1.3       HRV   \n",
       "4     4           Chloromethane     0.63  74-87-3  206544.0       PEL   \n",
       "\n",
       "  Description    Zip  \n",
       "0    business  55406  \n",
       "1    business  55406  \n",
       "2    business  55406  \n",
       "3    business  55406  \n",
       "4    business  55406  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9999b1",
   "metadata": {},
   "source": [
    "### Type of Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32230c6f",
   "metadata": {},
   "source": [
    "#### Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55acd5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features : 4\n"
     ]
    }
   ],
   "source": [
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print('Num of Numerical Features :', len(num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61b91a",
   "metadata": {},
   "source": [
    "#### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42418987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Categorical Features : 4\n"
     ]
    }
   ],
   "source": [
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print('Num of Categorical Features :', len(cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27d6bab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parameter', 'CAS', 'HRV_Types', 'Description']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f31e9e",
   "metadata": {},
   "source": [
    "#### Discrete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea843636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Discrete Features : 2\n"
     ]
    }
   ],
   "source": [
    "discrete_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print('Num of Discrete Features :',len(discrete_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46840172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Zip']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53dd3f1",
   "metadata": {},
   "source": [
    "#### Continues Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb7c4f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Continuous Features : 2\n"
     ]
    }
   ],
   "source": [
    "continuous_features=[feature for feature in num_features if feature not in discrete_features]\n",
    "print('Num of Continuous Features :',len(continuous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04aa3f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Results', 'HRV']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9eb1c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Results</th>\n",
       "      <th>CAS</th>\n",
       "      <th>HRV</th>\n",
       "      <th>HRV_Types</th>\n",
       "      <th>Description</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1,2,4-Trimethylbenzene</td>\n",
       "      <td>1.40</td>\n",
       "      <td>95-63-6</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>REL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2-Propanol</td>\n",
       "      <td>87.60</td>\n",
       "      <td>67-63-0</td>\n",
       "      <td>980000.0</td>\n",
       "      <td>REL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Acetone</td>\n",
       "      <td>8.40</td>\n",
       "      <td>67-64-1</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>REL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Benzene</td>\n",
       "      <td>0.87</td>\n",
       "      <td>71-43-2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>HRV</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Chloromethane</td>\n",
       "      <td>0.63</td>\n",
       "      <td>74-87-3</td>\n",
       "      <td>206544.0</td>\n",
       "      <td>PEL</td>\n",
       "      <td>business</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date               Parameter  Results      CAS       HRV HRV_Types  \\\n",
       "0     4  1,2,4-Trimethylbenzene     1.40  95-63-6  125000.0       REL   \n",
       "1     4              2-Propanol    87.60  67-63-0  980000.0       REL   \n",
       "2     4                 Acetone     8.40  67-64-1  590000.0       REL   \n",
       "3     4                 Benzene     0.87  71-43-2       1.3       HRV   \n",
       "4     4           Chloromethane     0.63  74-87-3  206544.0       PEL   \n",
       "\n",
       "  Description    Zip  \n",
       "0    business  55406  \n",
       "1    business  55406  \n",
       "2    business  55406  \n",
       "3    business  55406  \n",
       "4    business  55406  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b03c27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "date_mapping = {'Feb14': 1, 'May14': 2, 'Aug14': 3, 'Nov13': 4}\n",
    "\n",
    "# Replace the values in the 'Date' column with numerical values\n",
    "df['Date'] = df['Date'].replace(date_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989b7df",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1842c42",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13ca1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3175.6410045611533\n",
      "R-squared: 0.046515494984415984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df[['Parameter', 'CAS', 'HRV_Types', 'Date', 'Zip']]\n",
    "y = df['Results']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps for categorical variables\n",
    "categorical_features = ['Parameter', 'CAS', 'HRV_Types']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps for all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create a pipeline with preprocessing and linear regression model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', LinearRegression())])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c8047f2",
   "metadata": {},
   "source": [
    "The results of the linear regression model provide insights into its performance:\n",
    "\n",
    "1. **Mean Squared Error (MSE)**:\n",
    "   - The MSE measures the average squared difference between the actual and predicted values. In this case, the MSE is approximately 3175.64. It indicates the average squared error of the model's predictions. A lower MSE value indicates better performance, but the interpretation of MSE depends on the scale of the target variable.\n",
    "\n",
    "2. **R-squared (R²)**:\n",
    "   - The R-squared value measures the proportion of the variance in the target variable that is explained by the model. In this case, the R² value is approximately 0.047, which means that the model explains only about 4.7% of the variance in the 'Results' variable. A higher R² value closer to 1 indicates better fit, but R² should be interpreted in conjunction with other metrics and domain knowledge.\n",
    "\n",
    "Based on these results:\n",
    "- The linear regression model does not perform well in explaining the variance in the 'Results' variable, as indicated by the low R-squared value.\n",
    "- The MSE value indicates that the model's predictions have a relatively high average squared error.\n",
    "\n",
    "Possible reasons for the model's poor performance could include:\n",
    "- Insufficient or irrelevant features: The selected features ('Parameter', 'CAS', 'HRV_Types', 'Date', and 'Zip') may not be strongly correlated with the target variable, leading to poor predictive performance.\n",
    "- Linear assumption: The relationship between the predictors and the target variable may not be linear, violating the assumptions of linear regression.\n",
    "- Overfitting or underfitting: The model may be either too complex or too simple to capture the underlying patterns in the data.\n",
    "- Data quality issues: Missing values, outliers, or other data quality issues may affect the model's performance.\n",
    "\n",
    "To improve the model's performance, you could consider:\n",
    "- Feature engineering: Creating new features or transforming existing ones to better capture the relationship with the target variable.\n",
    "- Feature selection: Selecting the most relevant features based on domain knowledge or feature importance techniques.\n",
    "- Trying different algorithms: Experimenting with other regression algorithms that can capture non-linear relationships.\n",
    "- Data preprocessing: Handling missing values, outliers, or other data quality issues more effectively.\n",
    "\n",
    "Additionally, it's essential to consider the context of the problem and domain-specific knowledge when interpreting the model's results and deciding on further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42aed452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3176.4666230190055\n",
      "R-squared: 0.04626760348613701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df[['Parameter', 'CAS', 'HRV_Types', 'Date', 'Zip']]\n",
    "y = df['Results']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps for categorical variables\n",
    "categorical_features = ['Parameter', 'CAS', 'HRV_Types']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps for all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create a pipeline with preprocessing and Random Forest model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "726c7e6b",
   "metadata": {},
   "source": [
    "The results of the Random Forest algorithm are as follows:\n",
    "\n",
    "Mean Squared Error (MSE): The MSE is approximately 3176.47. It measures the average squared difference between the actual and predicted values. Similar to the linear regression model, this value indicates the average squared error of the model's predictions.\n",
    "R-squared (R²): The R-squared value is approximately 0.0463, indicating that the model explains only about 4.63% of the variance in the 'Results' variable. This value is also quite low, suggesting that the model does not perform well in explaining the variance in the target variable.\n",
    "Comparing these results with the linear regression model, we observe that both models have similar performance in terms of MSE and R². However, neither model performs well in explaining the variance in the target variable, as indicated by the low R-squared values.\n",
    "\n",
    "Possible reasons for the models' poor performance could include:\n",
    "\n",
    "Insufficient or irrelevant features: The selected features ('Parameter', 'CAS', 'HRV_Types', 'Date', and 'Zip') may not adequately capture the relationship with the target variable.\n",
    "Non-linear relationships: The relationships between the predictors and the target variable may be non-linear, and Random Forest may not capture these relationships effectively without further feature engineering or model tuning.\n",
    "Overfitting or underfitting: The models may be either too complex or too simple to capture the underlying patterns in the data.\n",
    "To improve model performance, you could consider:\n",
    "\n",
    "Feature engineering: Creating new features or transforming existing ones to better capture the relationship with the target variable.\n",
    "Hyperparameter tuning: Optimizing the hyperparameters of the Random Forest model using techniques like grid search or random search.\n",
    "Trying different algorithms: Experimenting with other regression algorithms or ensemble methods that may better capture the underlying patterns in the data.\n",
    "Additionally, it's crucial to consider the context of the problem and domain-specific knowledge when interpreting the models' results and deciding on further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2663ebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00       954\n",
      "    Marginal       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           1.00       958\n",
      "   macro avg       0.50      0.50      0.50       958\n",
      "weighted avg       0.99      1.00      0.99       958\n",
      "\n",
      "Accuracy: 0.9958246346555324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target variable based on VOC level classifications\n",
    "def classify_voc_level(results):\n",
    "    if results < 300:\n",
    "        return 'Low'\n",
    "    elif 300 <= results < 500:\n",
    "        return 'Acceptable'\n",
    "    elif 500 <= results < 1000:\n",
    "        return 'Marginal'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['VOC_Level'] = df['Results'].apply(classify_voc_level)\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df[['Parameter', 'CAS', 'HRV_Types', 'Date', 'Zip']]\n",
    "y = df['VOC_Level']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps for categorical variables\n",
    "# (Same as before)\n",
    "\n",
    "# Define the Random Forest Classifier model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a pipeline with preprocessing and Random Forest Classifier\n",
    "# (Same as before)\n",
    "\n",
    "# Fit the model on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "071f5369",
   "metadata": {},
   "source": [
    "The provided classification report and accuracy score reveal a high-performing model overall, achieving an accuracy of approximately 99.58%. However, it exhibits challenges in accurately classifying instances of the minority class \"Marginal\", with low precision, recall, and F1-score. This indicates potential issues stemming from class imbalance, as the \"Marginal\" class comprises only 4 instances. While the model excels in identifying instances of the majority class \"Low\", it struggles with the nuanced distinctions of the \"Marginal\" class. To enhance performance, addressing class imbalance through techniques like data augmentation or adjusting class weights could be beneficial. Additionally, further analysis is warranted to understand the specific factors contributing to the model's difficulty in classifying \"Marginal\" instances, potentially involving feature importance assessment and examining data distributions across classes. Such improvements would bolster the model's reliability and applicability in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "963a6fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00       954\n",
      "    Marginal       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           1.00       958\n",
      "   macro avg       0.50      0.50      0.50       958\n",
      "weighted avg       0.99      1.00      0.99       958\n",
      "\n",
      "Accuracy: 0.9958246346555324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target variable into numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Create a pipeline with preprocessing and Random Forest Classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_encoded = pipeline.predict(X_test)\n",
    "\n",
    "# Decode predicted labels back to original classes\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eba4e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Zip               Parameter     Results\n",
      "2    55401  1,3,5-Trimethylbenzene  415.000000\n",
      "6    55401          4-Ethyltoluene  306.000000\n",
      "25   55401              m&p-Xylene  104.122500\n",
      "16   55401            Ethylbenzene  102.000000\n",
      "14   55401                 Ethanol   63.777778\n",
      "..     ...                     ...         ...\n",
      "567  55455  Trichlorofluoromethane    1.100000\n",
      "568  55455               n-Heptane    1.000000\n",
      "569  55455                n-Hexane    0.980000\n",
      "560  55455                 Benzene    0.970000\n",
      "557  55455              2-Hexanone    0.810000\n",
      "\n",
      "[570 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Zip' and 'Parameter', and calculate the mean of 'Results' for each group\n",
    "report = df.groupby(['Zip', 'Parameter'])['Results'].mean().reset_index()\n",
    "\n",
    "# Sort the report by 'Zip' and descending 'Results' to find the highest mean 'Results' for each 'Zip'\n",
    "report_sorted = report.sort_values(by=['Zip', 'Results'], ascending=[True, False])\n",
    "\n",
    "print(report_sorted)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a24ceb7",
   "metadata": {},
   "source": [
    "Below is the code that classifies the Zip codes based on the VOC levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86e699cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code: 55415.0, Classification: Low\n",
      "Zip Code: 55454.0, Classification: Low\n",
      "Zip Code: 55455.0, Classification: Low\n",
      "Zip Code: 55422.0, Classification: Low\n",
      "Zip Code: 55416.0, Classification: Low-Medium\n",
      "Zip Code: 55411.0, Classification: Low-Medium\n",
      "Zip Code: 55408.0, Classification: Low-Medium\n",
      "Zip Code: 55404.0, Classification: Low-Medium\n",
      "Zip Code: 55413.0, Classification: Medium\n",
      "Zip Code: 55405.0, Classification: Medium\n",
      "Zip Code: 55414.0, Classification: Medium\n",
      "Zip Code: 55410.0, Classification: Medium\n",
      "Zip Code: 55430.0, Classification: Medium-High\n",
      "Zip Code: 55418.0, Classification: Medium-High\n",
      "Zip Code: 55412.0, Classification: Medium-High\n",
      "Zip Code: 55419.0, Classification: Medium-High\n",
      "Zip Code: 55406.0, Classification: High\n",
      "Zip Code: 55403.0, Classification: High\n",
      "Zip Code: 55409.0, Classification: High\n",
      "Zip Code: 55417.0, Classification: High\n",
      "Zip Code: 55401.0, Classification: High\n",
      "Zip Code: 55407.0, Classification: High\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average VOC level for each zip code\n",
    "average_voc_per_zip = df.groupby('Zip')['Results'].mean().reset_index()\n",
    "\n",
    "# Sort zip codes based on average VOC levels\n",
    "sorted_zip_codes = average_voc_per_zip.sort_values(by='Results')\n",
    "\n",
    "# Assign classification labels\n",
    "classification_labels = ['Low', 'Low-Medium', 'Medium', 'Medium-High', 'High']\n",
    "num_classes = len(classification_labels)\n",
    "class_interval = len(sorted_zip_codes) // num_classes\n",
    "\n",
    "# Initialize a dictionary to store classification labels for each zip code\n",
    "zip_code_classifications = {}\n",
    "\n",
    "# Assign classification labels based on ranking\n",
    "for i in range(len(sorted_zip_codes)):\n",
    "    class_index = min(i // class_interval, num_classes - 1)\n",
    "    zip_code = sorted_zip_codes.iloc[i]['Zip']\n",
    "    zip_code_classifications[zip_code] = classification_labels[class_index]\n",
    "\n",
    "# Print zip codes with their classification labels\n",
    "for zip_code, classification in zip_code_classifications.items():\n",
    "    print(f\"Zip Code: {zip_code}, Classification: {classification}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "147fd44f",
   "metadata": {},
   "source": [
    "The code segments you provided compute the average VOC level for each zip code in the dataset, sort the zip codes based on their average VOC levels, assign classification labels to the zip codes, and then print each zip code along with its assigned classification label. The classification labels are based on predefined thresholds dividing the zip codes into categories such as 'Low', 'Low-Medium', 'Medium', 'Medium-High', and 'High' according to their average VOC levels.\n",
    "\n",
    "The output displays each zip code along with its corresponding classification label. For example, zip codes 55415.0, 55454.0, 55455.0, and 55422.0 are classified as 'Low', while zip codes 55416.0, 55411.0, 55408.0, and 55404.0 are classified as 'Low-Medium', and so on. This categorization allows for a simplified representation of VOC levels across different geographical areas, aiding in the interpretation and analysis of air quality data.\n",
    "\n",
    "VOCs are known to have adverse effects on human health and the environment. By accurately \n",
    "predicting VOC levels and identifying areas with high concentrations, this project can \n",
    "contribute to efforts aimed at mitigating air pollution and protecting public health\n",
    "\n",
    "The High classified areas can be considered as hotspot regions. Measures can be taken to take this into controll and further research is suggested upon the reasons of why there is high level of VOCs in that locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f2850",
   "metadata": {},
   "source": [
    "## Overall Summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e99b4756",
   "metadata": {},
   "source": [
    "In summary, the project aimed to build a predictive model to estimate VOC levels based on various factors, with the objective of identifying potential hotspots for high VOC concentrations and informing air pollution control measures. The project involved several key steps:\n",
    "\n",
    "Data Collection: Data on VOC levels and related factors such as location, date, and specific parameters were collected from relevant sources.\n",
    "\n",
    "Data Preprocessing: The collected data underwent preprocessing steps such as handling missing values, encoding categorical variables, and scaling numerical features to prepare it for modeling.\n",
    "\n",
    "Model Selection: Different machine learning algorithms were explored and evaluated to identify the most suitable model for predicting VOC levels. Techniques such as cross-validation and hyperparameter tuning were employed to optimize model performance.\n",
    "\n",
    "Model Training and Evaluation: The selected model was trained on the preprocessed data and evaluated using appropriate metrics such as accuracy, precision, recall, and F1-score. The model's performance was assessed to ensure its reliability in estimating VOC levels.\n",
    "\n",
    "Results Interpretation: The trained model provided insights into the factors influencing VOC levels and identified potential hotspots for high VOC concentrations based on predictive estimates. This information can guide decision-making processes related to air pollution control measures, helping prioritize interventions in areas with the highest predicted VOC levels.\n",
    "\n",
    "Overall, the project successfully developed a predictive model for estimating VOC levels, which can serve as a valuable tool for environmental monitoring and management efforts aimed at mitigating air pollution and safeguarding public health."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
